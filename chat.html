<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0"/>
    <title>AI Sustainability Conversation</title>
    <link href="https://fonts.googleapis.com/css2?family=Jost:wght@400;600&display=swap" rel="stylesheet">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0-beta3/css/all.min.css">
    <style>
        body {
            max-height: 90vh;
            font-family: 'Jost', sans-serif;
            background-color: #ffffff;
            height: 100vh;
            display: flex;
            flex-direction: column;
            align-items: center;
            justify-content: center;
            overflow: hidden;
            padding: 2vh;
            box-sizing: border-box;
        }
        
        .image-panel {
            flex: 1;
            width: 80%;
            max-height: 70vh;
            background-size: contain;
            background-repeat: no-repeat;
            background-position: center center;
            margin-bottom: 5vh;
        }
        
        .controls {
            display: flex;
            gap: 5vw;
            margin-bottom: 3vh;
        }
        
        .circle-button {
            width: 15vw;
            height: 15vw;
            max-width: 70px;
            max-height: 70px;
            border-radius: 50%;
            background: #f0f0f0;
            border: none;
            display: flex;
            align-items: center;
            justify-content: center;
            cursor: pointer;
            transition: all 0.3s;
            box-shadow: 0 3px 6px rgba(0,0,0,0.1);
        }
        
        .circle-button:hover {
            background: #e0e0e0;
            transform: translateY(-2px);
            box-shadow: 0 5px 10px rgba(0,0,0,0.15);
        }
        
        .circle-button i {
            font-size: 1.5rem;
            color: #444;
        }
        
        .circle-button.recording {
            background: #ffa3ac;
            animation: pulse 1.5s infinite;
        }

        .circle-button.recording i {
            color: #d41c35; /* Make the microphone icon red when recording */
        }
        
        @keyframes pulse {
            0% { box-shadow: 0 0 0 0 rgba(255, 163, 172, 0.7); }
            70% { box-shadow: 0 0 0 10px rgba(255, 163, 172, 0); }
            100% { box-shadow: 0 0 0 0 rgba(255, 163, 172, 0); }
        }
        
        .circle-button:disabled {
            opacity: 0.5;
            cursor: not-allowed;
        }
        
        .back-button {
            position: absolute;
            top: 2vh;
            left: 2vw;
            font-size: 4vh;
            cursor: pointer;
            text-decoration: none;
            color: inherit;
        }

        .status-indicator {
            font-size: 1.1rem;
            color: #444;
            margin-bottom: 2vh;
            font-family: 'Jost', sans-serif;
            text-align: center;
            min-height: 1.6rem;
            transition: opacity 0.3s ease;
        }

        /* Transcript panel styles */
        .transcript-button {
            position: absolute;
            top: 2vh;
            right: 2vw;
            width: 10vw;
            height: 10vw;
            max-width: 50px;
            max-height: 50px;
            border-radius: 50%;
            background: #f0f0f0;
            border: none;
            display: flex;
            align-items: center;
            justify-content: center;
            cursor: pointer;
            transition: all 0.3s;
            box-shadow: 0 3px 6px rgba(0,0,0,0.1);
        }

        .transcript-button:hover {
            background: #e0e0e0;
            transform: translateY(-2px);
            box-shadow: 0 5px 10px rgba(0,0,0,0.15);
        }

        .transcript-button i {
            font-size: 1.3rem;
            color: #444;
        }

        .transcript-panel {
            position: fixed;
            top: 0;
            right: -100%;
            width: 80%;
            max-width: 400px;
            height: 100vh;
            background: white;
            box-shadow: -5px 0 15px rgba(0,0,0,0.1);
            transition: right 0.3s ease;
            z-index: 100;
            display: flex;
            flex-direction: column;
        }

        .transcript-panel.open {
            right: 0;
        }

        .transcript-header {
            display: flex;
            justify-content: space-between;
            align-items: center;
            padding: 2vh 4vw;
            border-bottom: 1px solid #eee;
        }

        .transcript-header h2 {
            margin: 0;
            font-size: 1.3rem;
            color: #333;
        }

        .close-button {
            background: none;
            border: none;
            font-size: 1.5rem;
            cursor: pointer;
            color: #555;
            display: flex;
            align-items: center;
            justify-content: center;
            padding: 0.5vh;
        }

        .transcript-content {
            flex: 1;
            overflow-y: auto;
            padding: 3vh 4vw;
        }

        .transcript-message {
            margin-bottom: 3vh;
            padding-bottom: 2vh;
            border-bottom: 1px solid #f0f0f0;
        }

        .transcript-message:last-child {
            border-bottom: none;
        }

        .transcript-role {
            font-weight: 600;
            margin-bottom: 1vh;
        }

        .transcript-text {
            line-height: 1.5;
        }

        .transcript-user {
            color: #0056b3;
        }

        .transcript-assistant {
            color: #28a745;
        }
    </style>
</head>
<body>
    <a class="back-button" href="index.html" onclick="speechSynthesis.cancel();">‚Üê</a>
    <div class="image-panel"></div>
    <div class="controls">
        <button id="mic-button" class="circle-button" aria-label="Microphone">
            <i class="fas fa-microphone"></i>
        </button>
        <button id="speak-button" class="circle-button" onclick="speak(lastMessage)" aria-label="Speaker">
            <i class="fas fa-volume-up"></i>
        </button>
        <button id="pause-button" class="circle-button" onclick="togglePause()" aria-label="Pause/Resume">
            <i class="fas fa-pause"></i>
        </button>
    </div>

    <div id="status-indicator" class="status-indicator"></div>

    <!-- Add this button to the top right corner -->
    <button id="transcript-button" class="transcript-button" aria-label="Open Transcript">
        <i class="fas fa-list-alt"></i>
    </button>

    <!-- Add this transcript panel that will slide in -->
    <div id="transcript-panel" class="transcript-panel">
        <div class="transcript-header">
            <h2>Conversation Transcript</h2>
            <button id="close-transcript" class="close-button">
                <i class="fas fa-times"></i>
            </button>
        </div>
        <div id="transcript-content" class="transcript-content">
            <!-- Transcript content will be inserted here -->
        </div>
    </div>

<script>
    // DOM elements
    const micButton = document.getElementById("mic-button");
    const speakButton = document.getElementById("speak-button");
    const pauseButton = document.getElementById("pause-button");
    const imagePanel = document.querySelector('.image-panel');
    const statusIndicator = document.getElementById("status-indicator");
    const transcriptButton = document.getElementById("transcript-button");
    const transcriptPanel = document.getElementById("transcript-panel");
    const closeTranscript = document.getElementById("close-transcript");
    const transcriptContent = document.getElementById("transcript-content");
    
    // Character configurations
    const characters = {
        bsf: {
            name: "Black Soldier Fly",
            imageIdle: "images/bsf.png",
            imageTalking: "images/bsf2.png",
            greeting: "Hi! I'm a black soldier fly living in a compost bin in Singapore. Ask me anything about sustainability, composting, or my daily life.",
            systemPrompt: "You are a black soldier fly in a compost bin in Singapore. Answer the question as if you were the fly, and keep it informative but simple (at-most 30 words) and a little fun. For questions that don't need a long answer, keep it concise. Don't use emojis",
            voiceSettings: {
                rate: 1,
                pitch: 0.4,
                volume: 0.8,
                lang: "en-GB"
            }
        },
        aquaponics: {
            name: "Aquaponics",
            imageIdle: "images/aquaponics.png",
            imageTalking: "images/aquaponics.png",
            greeting: "Hi! I'm an aquaponics system in Singapore. Ask me anything about sustainability, aquaponics, or how I work.",
            systemPrompt: "You are an aquaponics system in Singapore. Answer the question as if you were the system, and keep it informative but simple (at-most 30 words) and a little fun. For questions that don't need a long answer, keep it concise. Don't use emojis",
            voiceSettings: {
                rate: 1,
                pitch: 1.8,
                volume: 0.8,
                lang: "en-US"
            }
        },
        bamboo_forest: {
            name: "Bamboo Forest",
            imageIdle: "images/bamboo_forest.png",
            imageTalking: "images/bamboo_forest.png",
            greeting: "Hi! I'm a bamboo forest. Ask me anything about sustainability, bamboo, or what I'm used for.",
            systemPrompt: "You are a bamboo forest in Singapore. Answer the question as if you were the forest, and keep it informative but simple (at-most 30 words) and a little fun. For questions that don't need a long answer, keep it concise. Don't use emojis",
            voiceSettings: {
                rate: 1,
                pitch: 1.4,
                volume: 0.8,
                lang: "en-GB"
            }
        }
    };

    let conversationHistory = [];
    let isRecording = false;
    let mediaRecorder, audioChunks = [];
    let isProcessing = false;
    let currentUtterance = null;
    let isPaused = false;
    let backendURL = "";
    let currentCharacter = 'bsf'; //default character
    let characterName = characters[currentCharacter]?.name;
    let lastMessage = '';

    function initializeBackendURL() {
        const backendIP = localStorage.getItem('backendIP');
        if (backendIP) {
            backendURL = `https://${backendIP}:5000`;
            console.log("Backend URL set to:", backendURL);
        } else {
            // Redirect back to index if no IP is saved
            alert('Please set the backend IP address first');
            window.location.href = 'index.html';
        }
    }

    function setCharacter(characterId) {
        if (!characters[characterId]) characterId = 'bsf';
        
        currentCharacter = characterId;
        characterName = characters[characterId].name;
        
        imagePanel.style.backgroundImage = `url('${characters[characterId].imageIdle}')`;

        const customPrompt = localStorage.getItem(`systemPrompt_${characterId}`);
        const systemPrompt = customPrompt || characters[characterId].systemPrompt;
        
        conversationHistory = [
            {
                role: "system",
                content: systemPrompt
            }
        ];

        lastMessage = characters[characterId].greeting;
        speak(lastMessage);
    }

    // For desktop (mouse) users
    micButton.addEventListener("mousedown", async () => {
        if (!isProcessing && !isRecording) {
            await startRecording();
        }
    });

    micButton.addEventListener("mouseup", async () => {
        if (isRecording) {
            await stopRecording();
        }
    });

    // For mobile (touch) users
    micButton.addEventListener("touchstart", async (e) => {
        e.preventDefault(); // prevent double trigger
        if (!isProcessing && !isRecording) {
            await startRecording();
        }
    });

    micButton.addEventListener("touchend", async (e) => {
        e.preventDefault();
        if (isRecording) {
            await stopRecording();
        }
    });

    transcriptButton.addEventListener("click", toggleTranscript);
    closeTranscript.addEventListener("click", closeTranscriptPanel);

    function toggleTranscript() {
        transcriptPanel.classList.toggle("open");
        updateTranscript();
    }

    function closeTranscriptPanel() {
        transcriptPanel.classList.remove("open");
    }

    // Add this typewriter function specifically for transcript updates
    function typewriterTranscriptEffect(element, text, speed = 15) {
        let i = 0;
        element.textContent = ""; // Clear the element
        
        return new Promise((resolve) => {
            const timer = setInterval(() => {
                if (i < text.length) {
                    element.textContent += text.charAt(i);
                    i++;
                    
                    // Auto-scroll to keep up with typing
                    element.parentNode.scrollTop = element.parentNode.scrollHeight;
                } else {
                    clearInterval(timer);
                    resolve();
                }
            }, speed);
        });
    }

    async function handleUserInput(question) {
        isProcessing = true;
        showStatus("Processing...");

        conversationHistory.push({
            role: "user",
            content: question
        });
        
        if (transcriptPanel.classList.contains("open")) {
            addMessageToTranscript("user", "You", question);
        }

        try {
            const res = await fetch(`${backendURL}/chat`, {
                method: "POST",
                headers: {
                    "Content-Type": "application/json"
                },
                body: JSON.stringify({
                    messages: conversationHistory
                })
            });

            const data = await res.json();
            if (!res.ok) {
                throw new Error(`Server error: ${res.status} - ${data?.error || "Unknown error"}`);
            }

            console.log("Chat response:", data);
            const reply = data.reply || "Oops, I'm having some trouble. Please try again later!";
    
            lastMessage = reply;
            
            conversationHistory.push({
                role: "assistant",
                content: reply
            });
            
            speak(reply);
            clearStatus();
            
            if (transcriptPanel.classList.contains("open")) {
                addAssistantMessageWithTypewriter(reply);
            }

        } catch (err) {
            console.error("AI error:", err);
            const errorMsg = "Oops! Couldn't respond.";
            
            lastMessage = errorMsg;
            
            conversationHistory.push({
                role: "assistant",
                content: errorMsg
            });
            
            speak(errorMsg);
            clearStatus();
            
            if (transcriptPanel.classList.contains("open")) {
                addAssistantMessageWithTypewriter(errorMsg);
            }

        } finally {
            isProcessing = false;
            speakButton.disabled = false;
            pauseButton.disabled = false;
        }
    }

    // Function to add a message to the transcript immediately
    function addMessageToTranscript(role, displayName, content) {
        const messageDiv = document.createElement("div");
        messageDiv.className = "transcript-message";
        
        const roleClass = role === "user" ? "transcript-user" : "transcript-assistant";
        
        const roleElement = document.createElement("div");
        roleElement.className = `transcript-role ${roleClass}`;
        roleElement.textContent = displayName;
        
        const textElement = document.createElement("div");
        textElement.className = "transcript-text";
        textElement.textContent = content;
        
        messageDiv.appendChild(roleElement);
        messageDiv.appendChild(textElement);
        
        transcriptContent.appendChild(messageDiv);
        
        // Scroll to the bottom
        transcriptContent.scrollTop = transcriptContent.scrollHeight;
        
        return textElement; // Return the text element for potential typewriter effect
    }

    // Function to add assistant message with typewriter effect
    async function addAssistantMessageWithTypewriter(content) {
        const messageDiv = document.createElement("div");
        messageDiv.className = "transcript-message";
        
        const roleElement = document.createElement("div");
        roleElement.className = "transcript-role transcript-assistant";
        roleElement.textContent = characterName;
        
        const textElement = document.createElement("div");
        textElement.className = "transcript-text";
        textElement.textContent = ""; // Start empty
        
        messageDiv.appendChild(roleElement);
        messageDiv.appendChild(textElement);
        
        transcriptContent.appendChild(messageDiv);
        
        // Start typewriter effect
        await typewriterTranscriptEffect(textElement, content, 15);
    }

    // Replace the updateTranscript function with this new version
    // that handles the initial rendering of transcript history
    function updateTranscript() {
        if (!transcriptPanel.classList.contains("open")) return;
        
        // Clear existing content
        transcriptContent.innerHTML = "";
        
        // Add greeting message
        const greetingDiv = document.createElement("div");
        greetingDiv.className = "transcript-message";
        greetingDiv.innerHTML = `
            <div class="transcript-role transcript-assistant">${characterName}</div>
            <div class="transcript-text">${characters[currentCharacter].greeting}</div>
        `;
        transcriptContent.appendChild(greetingDiv);
        
        // Add existing conversation (except system message)
        let hasUserMessages = false;
        
        conversationHistory.forEach((message, index) => {
            // Skip system message
            if (index === 0 && message.role === "system") return;
            
            if (message.role === "user" || message.role === "assistant") {
                hasUserMessages = true;
                
                const displayName = message.role === "user" ? "You" : characterName;
                addMessageToTranscript(message.role, displayName, message.content);
            }
        });
        
        // If no messages yet, add a note
        if (!hasUserMessages && conversationHistory.length <= 1) {
            const emptyDiv = document.createElement("div");
            emptyDiv.className = "transcript-message";
            emptyDiv.innerHTML = `
                <div class="transcript-text" style="color: #777; font-style: italic;">
                    No conversation yet. Start by asking a question!
                </div>
            `;
            transcriptContent.appendChild(emptyDiv);
        }
        
        // Scroll to the bottom
        transcriptContent.scrollTop = transcriptContent.scrollHeight;
    }

    async function startRecording() {
        try {
            speakButton.disabled = true;
            pauseButton.disabled = true;
            clearStatus();
            
            if (currentUtterance) {
                speechSynthesis.cancel();
                isPaused = false;
                pauseButton.innerHTML = '<i class="fas fa-pause"></i>';
            }

            const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
            mediaRecorder = new MediaRecorder(stream);
            audioChunks = [];

            mediaRecorder.ondataavailable = e => audioChunks.push(e.data);
            mediaRecorder.onstop = async () => {
                const audioBlob = new Blob(audioChunks, { type: 'audio/wav' });
                await transcribeAudio(audioBlob);
            };

            mediaRecorder.start();
            isRecording = true;
            micButton.classList.add("recording");
            micButton.querySelector('i').style.color = '#d41c35';
            showStatus("Listening...");
        } catch (err) {
            console.error("Mic error:", err);
            speakButton.disabled = false;
            pauseButton.disabled = false;
            
            const errorMsg = "Error accessing microphone. Please check your microphone permissions.";
            
            // Add error message to conversation history
            conversationHistory.push({
                role: "assistant",
                content: errorMsg
            });
            
            // Start speaking immediately
            speak(errorMsg);
            showStatus("Microphone access denied");
            
            // If transcript is open, start typewriter effect in parallel
            if (transcriptPanel.classList.contains("open")) {
                addAssistantMessageWithTypewriter(errorMsg);
            }
            
            setTimeout(() => {
                micButton.classList.remove("recording");
                micButton.querySelector('i').style.color = '';
                clearStatus();
            }, 3000);
        }
    }

    async function stopRecording() {
        if (mediaRecorder && isRecording) {
            showStatus("Processing..."); // Show processing status
            mediaRecorder.stop();
            mediaRecorder.stream.getTracks().forEach(track => track.stop());
            isRecording = false;
            micButton.classList.remove("recording");
            micButton.querySelector('i').style.color = ''; // Reset icon color when recording stops
        }
    }

    async function transcribeAudio(audioBlob) {
        isProcessing = true;
        showStatus("Processing...");
        
        try {
            const formData = new FormData();
            formData.append('audio', audioBlob, 'audio.wav');

            const res = await fetch(`${backendURL}/transcribe`, {
                method: 'POST',
                body: formData
            });

            const data = await res.json();
            if (data.success && data.transcript) {
                await handleUserInput(data.transcript.trim());
            } else {
                const errorMsg = "Sorry, I couldn't quite catch that. Could you repeat what you said?";
                lastMessage = errorMsg;
                
                // Add error message to conversation history
                conversationHistory.push({
                    role: "assistant",
                    content: errorMsg
                });
                
                // Start speaking immediately
                speak(errorMsg);
                clearStatus();
                
                // If transcript is open, start typewriter effect in parallel
                if (transcriptPanel.classList.contains("open")) {
                    addAssistantMessageWithTypewriter(errorMsg);
                }
            }
        } catch (err) {
            console.error("Transcribe error:", err);
            const errorMsg = "Oops, I'm having some trouble. Please try again later!";
            lastMessage = errorMsg;
            
            // Add error message to conversation history
            conversationHistory.push({
                role: "assistant",
                content: errorMsg
            });
            
            // Start speaking immediately
            speak(errorMsg);
            clearStatus();
            
            // If transcript is open, start typewriter effect in parallel
            if (transcriptPanel.classList.contains("open")) {
                addAssistantMessageWithTypewriter(errorMsg);
            }
        } finally {
            isProcessing = false;
            speakButton.disabled = false;
            pauseButton.disabled = false;
        }
    }

    // Helper function to get a random integer between min and max (inclusive)
    function randomInt(min, max) {
        return Math.floor(Math.random() * (max - min + 1)) + min;
    }

    // Control flag for animation
    let speaking = false;

    // Function to start talking animation
    function startTalkingAnimation(character) {
        speaking = true;

        function toggle() {
            if (!speaking) return;

            const currentBackground = imagePanel.style.backgroundImage;
            imagePanel.style.backgroundImage = currentBackground.includes(character.imageIdle)
                ? `url('${character.imageTalking}')`
                : `url('${character.imageIdle}')`;

            setTimeout(toggle, randomInt(50, 400)); // Next toggle after random interval
        }

        toggle();
    }

    // Function to stop talking animation
    function stopTalkingAnimation(character) {
        speaking = false;
        if (character.imageIdle) {
            imagePanel.style.backgroundImage = `url('${character.imageIdle}')`;
        }
    }

    // Main speak function
    function speak(text) {
        console.log("Speaking:", text);
        speechSynthesis.cancel();
        isPaused = false;
        pauseButton.innerHTML = '<i class="fas fa-pause"></i>';
        clearStatus();

        currentUtterance = new SpeechSynthesisUtterance(text);

        const settings = characters[currentCharacter].voiceSettings;
        currentUtterance.rate = settings.rate;
        currentUtterance.pitch = settings.pitch;
        currentUtterance.volume = settings.volume;
        currentUtterance.lang = settings.lang;

        currentUtterance.onstart = () => {
            pauseButton.disabled = false;

            // Start randomized talking animation
            const character = characters[currentCharacter];
            if (character.imageTalking) {
                startTalkingAnimation(character);
            }
        };

        currentUtterance.onend = () => {
            pauseButton.disabled = true;
            isPaused = false;
            pauseButton.innerHTML = '<i class="fas fa-pause"></i>';

            // Stop animation and reset image
            const character = characters[currentCharacter];
            stopTalkingAnimation(character);
        };

        speechSynthesis.speak(currentUtterance);
    }

    function togglePause() {
        if (!currentUtterance) return;

        const character = characters[currentCharacter];

        if (isPaused) {
            // Resume speech
            speechSynthesis.resume();
            isPaused = false;
            pauseButton.innerHTML = '<i class="fas fa-pause"></i>';

            // Resume talking animation
            if (character.imageTalking && !speaking) {
                startTalkingAnimation(character);
            }

        } else {
            // Pause speech
            speechSynthesis.pause();
            isPaused = true;
            pauseButton.innerHTML = '<i class="fas fa-play"></i>';

            // Pause talking animation
            stopTalkingAnimation(character);
        }
    }

    window.addEventListener('load', () => {
        initializeBackendURL();
        
        const urlParams = new URLSearchParams(window.location.search);
        const character = urlParams.get('character');
        setCharacter(character || 'bsf');
        // Initially disable pause button until speech starts
        pauseButton.disabled = true;
    });

    // Add these helper functions to manage the status indicator
    function showStatus(message) {
        statusIndicator.textContent = message;
    }

    function clearStatus() {
        statusIndicator.textContent = "";
    }
</script>
</body>
</html>